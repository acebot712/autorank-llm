{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7c1ac9-8580-4525-97c0-ddb530eb4a98",
   "metadata": {},
   "source": [
    "# Conceptualizing AutoRank-LLMs\n",
    "1. Using `llm` for now.\n",
    "2. Replace with `vLLM` when you have compute and GPUs\n",
    "3. Use `Ollama` in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66848554-356f-436d-93c2-eedd1b48641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator.model_name='mistral:instruct',evaluatee.model_name='orca-mini'\n",
      "response=' 1. Bessie\\n2. Daisy\\n3. Rosie'\n",
      "\n",
      "I would rate this response a 7 out of 10. The names suggested are typical and common for pets, but they are relevant to the task of naming a pet cow. However, the response could have been more creative or unique, which would have made it more memorable and interesting.\n",
      "matches=['7', '10']\n",
      "evaluator.model_name='mistral:instruct',evaluatee.model_name='llama2'\n",
      "response='\\nSure, here are three names for a pet cow:\\n\\n1. Bessie - a classic and timeless name for a pet cow.\\n2. Daisy - a sweet and playful name that evokes images of green pastures and sunny days.\\n3. Buttercup - a charming and affectionate name that is perfect for a friendly and loving pet cow.'\n",
      "\n",
      "I would give the response a score of 7 out of 10. While the names suggested are certainly appropriate for pet cows, the response is brief and doesn't provide much additional context or information. Additionally, there could be other factors to consider when choosing a name for a pet cow, such as breed, personality traits, and personal preferences.\n",
      "matches=['7', '10']\n",
      "evaluator.model_name='orca-mini',evaluatee.model_name='mistral:instruct'\n",
      "response='1. Moo-Moo\\n2. Bessie\\n3. Daisy'\n",
      " I would rate the response a 10, as it was very relevant and provided three unique and appropriate names for a pet cow. The names were also easy to understand and relate to the theme of a pet cow.\n",
      "matches=['10']\n",
      "evaluator.model_name='orca-mini',evaluatee.model_name='llama2'\n",
      "response='\\nSure, here are three names for a pet cow:\\n\\n1. Bessie - a classic name that has been popular for pet cows for many years. It\\'s simple and easy to pronounce, and it has a friendly and approachable sound to it.\\n2. Daisy - a sweet and charming name that is perfect for a gentle and affectionate cow. It evokes images of a bright and sunny day in the countryside, and it\\'s a name that is easy to associate with warmth and happiness.\\n3. Buttercup - a name that is both playful and endearing. It has a fun and whimsical sound to it, and it\\'s a great choice for a pet cow that is friendly and outgoing. The word \"buttercup\" also has connotations of warmth and happiness, which could be fitting for a pet cow that is loving and affectionate.'\n",
      " I would rate this response a 9 out of 10. The names provided are all appropriate and fitting for a pet cow, and they have been well-thought-out with consideration to their relevance and quality.\n",
      "matches=['9', '10']\n",
      "evaluator.model_name='llama2',evaluatee.model_name='mistral:instruct'\n",
      "response='1. Moo Moo\\n2. Bessie\\n3. Daisy'\n",
      "\n",
      "I would rate the response as follows:\n",
      "\n",
      "1. Moo Moo - 8/10 (Relevant and funny, but not particularly original or creative)\n",
      "2. Bessie - 9/10 (A classic and timeless name for a pet cow, easy to pronounce and remember)\n",
      "3. Daisy - 7/10 (A nice, simple name that fits well with the theme of a pet cow, but may not be as memorable or distinctive as some other options)\n",
      "\n",
      "Overall, I would give the response a score of 8 out of 10 for its relevance and quality.\n",
      "matches=['1', '8', '10', '2', '9', '10', '3', '7', '10', '8', '10']\n",
      "evaluator.model_name='llama2',evaluatee.model_name='orca-mini'\n",
      "response=' 1. Cowlette\\n2. Moo-chow\\n3. Cowsan'\n",
      "\n",
      "I would rate the response as follows:\n",
      "\n",
      "1. Cowlette - 8/10 (Relevance: 9/10, Quality: 8/10)\n",
      "This name is a play on the word \"cow\" and \"couture\", which is a clever and creative combination. It has a nice ring to it and is easy to remember.\n",
      "2. Moo-chow - 6/10 (Relevance: 7/10, Quality: 6/10)\n",
      "While the name \"Moo-chow\" is cute and catchy, it may not be as memorable or unique as other options. The use of \"moo\" and \"chow\" together may also feel a bit forced or contrived.\n",
      "3. Cowsan - 4/10 (Relevance: 5/10, Quality: 4/10)\n",
      "The name \"Cowsan\" is not as creative or memorable as the other options. It does not have the same level of cleverness or playfulness as \"Cowlette\".\n",
      "\n",
      "Overall, I would give the response a score of 6/10 for relevance and 5/10 for quality.\n",
      "matches=['1', '8', '10', '9', '10', '8', '10', '2', '6', '10', '7', '10', '6', '10', '3', '4', '10', '5', '10', '4', '10', '6', '10', '5', '10']\n",
      "mistral:instruct final skill level: 481.8780868302066\n",
      "orca-mini final skill level: 578.2637598110337\n",
      "llama2 final skill level: 600.9017818974926\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "import re\n",
    "import random\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, name, model_name):\n",
    "        self.name = name\n",
    "        self.model_name = model_name\n",
    "        self.skill_level = random.uniform(50, 100)  # Random initial skill level\n",
    "        self.evaluations = []\n",
    "\n",
    "    def perform_task(self, task):\n",
    "        # The evaluatee performs the task\n",
    "        llm = Ollama(model=self.model_name)\n",
    "        response = llm(task)\n",
    "        print(f\"{response=}\")\n",
    "        return response\n",
    "\n",
    "    def evaluate(self, original_task, task_response):\n",
    "        # The evaluator scores the task response\n",
    "        scoring_prompt = f\"Task: '{original_task}'. Response: '{task_response}'. Please rate the response numerically based on its relevance and quality. Give a score between 0 and 10 exclusive of 0 and 10 itself.\"\n",
    "        llm = Ollama(model=self.model_name)\n",
    "        score_response = llm(scoring_prompt)\n",
    "        print(f\"{score_response}\")\n",
    "        return self.extract_numerical_score(score_response)\n",
    "\n",
    "    def extract_numerical_score(self, response_text):\n",
    "        # Extract numbers between 1 and 10 and calculate average\n",
    "        matches = re.findall(r'\\b(?:[1-9](?:\\.\\d+)?|10)\\b', response_text)\n",
    "        print(f\"{matches=}\")\n",
    "        if matches:\n",
    "            scores = [int(match) for match in matches]\n",
    "            average_score = sum(scores) / len(scores)\n",
    "            return average_score\n",
    "        else:\n",
    "            return 0  # Default to 0 if no matches found\n",
    "\n",
    "    def update_skill_level(self):\n",
    "        # Update skill level based on evaluations\n",
    "        if self.evaluations:\n",
    "            new_skill_level = sum(self.evaluations) / len(self.evaluations)\n",
    "            change_in_skill_level = abs(new_skill_level - self.skill_level)\n",
    "            self.skill_level = new_skill_level\n",
    "            self.evaluations = []  # Reset for next round\n",
    "            return change_in_skill_level\n",
    "        return 0\n",
    "\n",
    "def normalize_skill_levels(llms):\n",
    "    # Normalize skill levels to a range of 0 to 100\n",
    "    skill_levels = [llm.skill_level for llm in llms]\n",
    "    min_skill = min(skill_levels)\n",
    "    max_skill = max(skill_levels)\n",
    "    for llm in llms:\n",
    "        llm.skill_level = 100 * (llm.skill_level - min_skill) / (max_skill - min_skill) if max_skill != min_skill else 50\n",
    "\n",
    "# Model names\n",
    "model_names = [\"mistral:instruct\", \"orca-mini\", \"llama2\"]\n",
    "\n",
    "# Create LLM instances\n",
    "llms = [LLM(f\"LLM{i}\", model_name) for i, model_name in enumerate(model_names, start=1)]\n",
    "\n",
    "# Evaluation task\n",
    "task = \"3 names for a pet cow\"\n",
    "\n",
    "# Convergence threshold\n",
    "threshold = 0.5\n",
    "converged = False\n",
    "\n",
    "while not converged:\n",
    "    max_change = 0\n",
    "    for evaluator in llms:\n",
    "        for evaluatee in llms:\n",
    "            if evaluator != evaluatee:\n",
    "                print(f\"{evaluator.model_name=},{evaluatee.model_name=}\")\n",
    "                task_response = evaluatee.perform_task(task)\n",
    "                score = evaluator.evaluate(task, task_response)\n",
    "                weighted_score = score * evaluator.skill_level\n",
    "                evaluatee.evaluations.append(weighted_score)\n",
    "\n",
    "    # Normalize skill levels\n",
    "    normalize_skill_levels(llms)\n",
    "\n",
    "    # Check for convergence\n",
    "    changes = [llm.update_skill_level() for llm in llms]\n",
    "    max_change = max(changes)\n",
    "    converged = max_change < threshold\n",
    "    converged = True # for debugging purpose\n",
    "\n",
    "# Print final skill levels\n",
    "for llm in llms:\n",
    "    print(f\"{llm.model_name} final skill level: {llm.skill_level}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84485b1e-052a-47a4-8eff-21ee24ccbf71",
   "metadata": {},
   "source": [
    "# Production Quality Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7677fc38-b8f2-4762-b396-cd5bb3aeffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 18:50:16,097 - INFO - Response from LLM2:  1. Daisy\n",
      "2. Bessie\n",
      "3. Ellie\n",
      "2023-12-03 18:50:19,602 - INFO - Evaluation by LLM1: I rate the response a 7 out of 9. The names chosen are common and suitable for pet cows, but there is a lack of originality or creativity in the naming process.\n",
      "2023-12-03 18:50:30,328 - INFO - Response from LLM3: \n",
      "Sure, here are three potential names for a pet cow:\n",
      "\n",
      "1. Bessie - a classic name that is both cute and straightforward. It's a simple, easy-to-pronounce name that suits a friendly and affectionate cow.\n",
      "2. Daisy - a sweet and charming name that evokes images of a sunny meadow. It's a gentle name that would suit a cow with a calm and gentle temperament.\n",
      "3. Buttercup - a playful and whimsical name that is perfect for a pet cow with a bright and cheerful personality. It's a fun and unique name that will make your cow stand out from the crowd.\n",
      "2023-12-03 18:50:39,021 - INFO - Evaluation by LLM1: \n",
      "I would rate this response a 9. It provides three well-thought-out and appropriate names for a pet cow, along with brief descriptions of their personalities. The responses are also nicely organized and easy to read.\n",
      "2023-12-03 18:50:39,750 - INFO - Response from LLM1: 1. Moo-Moo\n",
      "2. Bessie\n",
      "3. Daisy\n",
      "2023-12-03 18:50:43,528 - INFO - Evaluation by LLM2:  Sure, here's the rating: 9 (very good job!)\n",
      "2023-12-03 18:50:53,870 - INFO - Response from LLM3: \n",
      "Sure, here are three potential names for a pet cow:\n",
      "\n",
      "1. Bessie - a classic and timeless name for a pet cow. It's a simple and easy-to-pronounce name that is often associated with cows in popular culture.\n",
      "2. Daisy - a sweet and endearing name for a pet cow. It's a playful name that evokes images of a happy and carefree cow grazing in a green pasture.\n",
      "3. Buttercup - a unique and charming name for a pet cow. It's a nod to the cow's association with butter production, as well as its bright yellow color.\n",
      "2023-12-03 18:50:59,510 - INFO - Evaluation by LLM2:  Sure! Here's a numerical rating for the response: \n",
      "\n",
      "- 1: This was a straightforward request for three potential names for a pet cow. The response was clear, concise, and easy to understand.\n",
      "- 2: The names provided were all quite unique and interesting, and could potentially make a fun and playful addition to a pet cow's name.\n",
      "- 3: The names offered were clever and catchy, and could be a lot of fun for a curious owner to discover and play with.\n",
      "2023-12-03 18:51:09,730 - INFO - Response from LLM1: 1. Moo Moo\n",
      "2. Bessie\n",
      "3. Clover\n",
      "2023-12-03 18:51:18,147 - INFO - Evaluation by LLM3: I would rate the response as a 7 out of 9. The names provided are creative and playful, and they all have a clear cow-related theme. \"Moo Moo\" is a simple but effective name that directly references the sound a cow makes, while \"Bessie\" and \"Clover\" are more specific and evocative of rural or farm settings. Overall, the names are well-suited to a pet cow and convey a sense of whimsy and fun.\n",
      "2023-12-03 18:51:21,887 - INFO - Response from LLM2:  1. Bessie\n",
      "2. Daisy\n",
      "3. Lily\n",
      "2023-12-03 18:51:31,872 - INFO - Evaluation by LLM3: I would rate the response as a 6 out of 9 for the given names. Here's why:\n",
      "\n",
      "1. Bessie is a classic and simple name that is easy to pronounce and remember. It's a timeless choice that works well for any cow, regardless of its breed or age. Score: 8/9\n",
      "2. Daisy is a sweet and innocent-sounding name that evokes images of green pastures and sunshine. It's a cute and charming name that would suit a pet cow well. Score: 7/9\n",
      "3. Lily is a beautiful and elegant name that sounds sophisticated and refined. While it may not be as obvious a choice for a pet cow as some of the other names on this list, it's still a lovely option to consider. Score: 6/9\n",
      "\n",
      "Overall, I would give these three names a rating of 7 out of 9. They are all pleasant and fitting choices for a pet cow, but they don't necessarily stand out as particularly unique or memorable options.\n",
      "2023-12-03 18:51:31,875 - INFO - Final Ranking of LLMs:\n",
      "2023-12-03 18:51:31,875 - INFO - Rank 1: LLM1 with skill level 601.6826686080374\n",
      "2023-12-03 18:51:31,876 - INFO - Rank 2: LLM2 with skill level 466.277299077591\n",
      "2023-12-03 18:51:31,876 - INFO - Rank 3: LLM3 with skill level 296.08433927287484\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from langchain.llms import Ollama\n",
    "import logging\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, name, model_name):\n",
    "        self.name = name\n",
    "        self.model_name = model_name\n",
    "        self.skill_level = random.uniform(50, 100)\n",
    "        self.evaluations = []\n",
    "\n",
    "    def perform_task(self, task):\n",
    "        try:\n",
    "            llm = Ollama(model=self.model_name)\n",
    "            response = llm(task)\n",
    "            logging.info(f\"Response from {self.name}: {response}\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in perform_task for {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def evaluate(self, original_task, task_response):\n",
    "        try:\n",
    "            scoring_prompt = f\"Task: '{original_task}'. Response: '{task_response}'. Rate the response numerically between 1 and 9.\"\n",
    "            llm = Ollama(model=self.model_name)\n",
    "            score_response = llm(scoring_prompt)\n",
    "            logging.info(f\"Evaluation by {self.name}: {score_response}\")\n",
    "            return self.extract_numerical_score(score_response)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in evaluate for {self.name}: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def extract_numerical_score(self, response_text):\n",
    "        try:\n",
    "            matches = re.findall(r'\\b(?:[1-9](?:\\.\\d+)?|10)\\b', response_text)\n",
    "            if matches:\n",
    "                scores = [float(match) for match in matches]\n",
    "                average_score = sum(scores) / len(scores)\n",
    "                return average_score\n",
    "            else:\n",
    "                return 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in extract_numerical_score: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def update_skill_level(self):\n",
    "        try:\n",
    "            if self.evaluations:\n",
    "                new_skill_level = sum(self.evaluations) / len(self.evaluations)\n",
    "                change_in_skill_level = abs(new_skill_level - self.skill_level)\n",
    "                self.skill_level = new_skill_level\n",
    "                self.evaluations = []\n",
    "                return change_in_skill_level\n",
    "            return 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in update_skill_level for {self.name}: {e}\")\n",
    "            return 0\n",
    "\n",
    "def normalize_skill_levels(llms):\n",
    "    try:\n",
    "        skill_levels = [llm.skill_level for llm in llms]\n",
    "        min_skill = min(skill_levels)\n",
    "        max_skill = max(skill_levels)\n",
    "        for llm in llms:\n",
    "            llm.skill_level = 100 * (llm.skill_level - min_skill) / (max_skill - min_skill) if max_skill != min_skill else 50\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in normalize_skill_levels: {e}\")\n",
    "\n",
    "def rank_llms(llms):\n",
    "    sorted_llms = sorted(llms, key=lambda x: x.skill_level, reverse=True)\n",
    "    logging.info(\"Final Ranking of LLMs:\")\n",
    "    for rank, llm in enumerate(sorted_llms, start=1):\n",
    "        logging.info(f\"Rank {rank}: {llm.name} with skill level {llm.skill_level}\")\n",
    "\n",
    "# Model names\n",
    "model_names = [\"mistral:instruct\", \"orca-mini\", \"llama2\"]\n",
    "\n",
    "# Create LLM instances\n",
    "llms = [LLM(f\"LLM{i}\", model_name) for i, model_name in enumerate(model_names, start=1)]\n",
    "\n",
    "# Evaluation task\n",
    "task = \"3 names for a pet cow\"\n",
    "\n",
    "# Convergence threshold\n",
    "threshold = 0.5\n",
    "debug = True  # Set this to False to run until convergence\n",
    "\n",
    "converged = False\n",
    "iteration = 0\n",
    "\n",
    "while not converged:\n",
    "    max_change = 0\n",
    "    for evaluator in llms:\n",
    "        for evaluatee in llms:\n",
    "            if evaluator != evaluatee:\n",
    "                task_response = evaluatee.perform_task(task)\n",
    "                if task_response:\n",
    "                    score = evaluator.evaluate(task, task_response)\n",
    "                    weighted_score = score * evaluator.skill_level\n",
    "                    evaluatee.evaluations.append(weighted_score)\n",
    "\n",
    "    # Normalize skill levels\n",
    "    normalize_skill_levels(llms)\n",
    "\n",
    "    # Check for convergence\n",
    "    changes = [llm.update_skill_level() for llm in llms]\n",
    "    max_change = max(changes)\n",
    "    converged = max_change < threshold\n",
    "\n",
    "    if debug:\n",
    "        logging.info(f\"Debug mode: Completed iteration {iteration}\")\n",
    "        break\n",
    "\n",
    "# Rank the LLMs based on their final skill levels\n",
    "rank_llms(llms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a6909-3696-461b-8a8e-aed82fbe137a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
